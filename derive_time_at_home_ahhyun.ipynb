{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8abfb1c3-78a3-4d09-8bdd-74a1078ffdef",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tracking Depression Study: Time At Home Data Wrangling\n",
    "\n",
    "**Author:** Dawson Haddox\n",
    "\n",
    "**Date:** 8/19/24 (12/20/25: Added a few comments / documentation)\n",
    "\n",
    "**Purpose:** This code identifies likely home locations in the Tracking Depression study by applying DBSCAN to nighttime GPS data. It loads each participant's GPS records, filters for nighttime hours, and clusters dense locations to infer home coordinates. These inferred home points are then mapped back to the full dataset to flag whether each GPS sample is \"at home\" based on proximity to any home location. Folium maps are generated to visualize the results for validation. Parameters for DBSCAN and proximity were derived using empirical guides (e.g., typical working hours, largest typical housing sizes) and visual inspection.\n",
    "\n",
    "**Note:** The code takes a long time to run on a normal laptop. There are ways to make it more efficient (e.g., parallel processing if resources are available, replacing row-wise operations), and it may run faster on the cluster. I'd recommend you start by running it on a subset of the data if you want to make changes to the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47558f06-4785-407c-9b63-5707f0959a4b",
   "metadata": {},
   "source": [
    "### Import Libraries & Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93c5fb4-7c89-477c-b268-17f35518062b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from geopy.distance import geodesic\n",
    "from shapely.geometry import MultiPoint\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from functools import lru_cache\n",
    "\n",
    "# Read & display data\n",
    "loc_df = pd.read_csv(\"/Users/dawsonhaddox/Documents/Jacobson Lab/Avoidance-Mediation/smoothed_loc_pull.csv\", usecols=lambda column: column != \"Unnamed: 0\")\n",
    "display(loc_df.head(), loc_df.shape)\n",
    "\n",
    "# Subset to save time while testing\n",
    "loc_df = loc_df[loc_df['uid'].between('0011@mlife', '0020@mlife')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57d3042-cf97-462e-bf76-7d132982f9ca",
   "metadata": {},
   "source": [
    "# Subset to Nighttime / Time Asleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1f4ee9-76eb-4dac-939d-915fd43c6194",
   "metadata": {},
   "source": [
    "## Default Nighttime Subset\n",
    "\n",
    "Subset to GPS observations between 10pm–7am.\n",
    "\n",
    "Seems to work well based on visual inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe7cebd-4819-47a4-9e68-01b00e30aeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'time' to datetime format\n",
    "loc_df['time'] = pd.to_datetime(loc_df['time'])\n",
    "\n",
    "# Define nighttime range (10pm–7am)\n",
    "night_start = pd.to_datetime(\"22:00:00\", format='%H:%M:%S').time()\n",
    "night_end = pd.to_datetime(\"07:00:00\", format='%H:%M:%S').time()\n",
    "\n",
    "# Filter data to nighttime hours (10pm–7am)\n",
    "loc_night = loc_df[(loc_df['time'].dt.time >= night_start) | (loc_df['time'].dt.time <= night_end)]\n",
    "\n",
    "# Display filtered dataframe\n",
    "display(loc_night.head(), loc_night.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27587201-020a-4ed8-88a9-da221beeeef5",
   "metadata": {},
   "source": [
    "## Garmin Sleep Subset\n",
    "\n",
    "Loads per-user sleep data from CSV files and checks whether each location timestamp falls within a recorded sleep session by computing sleep start and end times.\n",
    "\n",
    "This code might need refining if you want to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc18114b",
   "metadata": {},
   "source": [
    "**Garmin Sleep Columns:**\n",
    "\n",
    "1. _id: Unique identifier for each entry in the dataset.\n",
    "2. awakeDurationInSeconds: The duration of time the individual was awake during the sleep period, measured in seconds.\n",
    "3. **calendarDate:** The date (in the format YYYY-MM-DD) when the sleep session occurred.\n",
    "4. deepSleepDurationInSeconds: The amount of time spent in deep sleep during the session, measured in seconds.\n",
    "5. **durationInSeconds:** The total duration of the sleep session, measured in seconds.\n",
    "6. lightSleepDurationInSeconds: The time spent in light sleep, measured in seconds.\n",
    "7. **mlife_id:** An identifier that likely refers to the individual’s account or device ID within the system.\n",
    "8. remSleepInSeconds: The duration of REM (Rapid Eye Movement) sleep during the session, measured in seconds.\n",
    "9. sleepLevelsMap: A complex, nested JSON-like structure that likely contains detailed information about sleep stages at different times during the sleep session.\n",
    "10. **startTimeInSeconds:** The timestamp (in seconds since epoch) when the sleep session began.\n",
    "11. **startTimeOffsetInSeconds:** Time offset, possibly representing the time zone adjustment from UTC, measured in seconds.\n",
    "12. summaryId: Another unique identifier, likely for the summary of the session.\n",
    "13. timeOffsetSleepRespiration: A complex, nested structure indicating respiration rates at different time points during the sleep session.\n",
    "14. timeOffsetSleepSpo2: A nested structure representing blood oxygen saturation (SpO2) levels at different time points during the sleep session.\n",
    "15. unmeasurableSleepInSeconds: The duration of unmeasurable sleep periods, possibly due to errors or sensor issues, measured in seconds.\n",
    "16. validation: This field indicates the validation status of the sleep data, with values like “AUTO_TENTATIVE” or “ENHANCED_TENTATIVE,” likely showing how the data was processed or its reliability.\n",
    "\n",
    "**Errors:**\n",
    "- Error processing data for UID 0030@mlife: No columns to parse from file\n",
    "- Error processing data for UID 0138@mlife: No columns to parse from file\n",
    "- Error processing data for UID 0139@mlife: No columns to parse from file\n",
    "- Error processing data for UID 0161@mlife: No columns to parse from file\n",
    "- Error processing data for UID 0167@mlife: No columns to parse from file\n",
    "- Error processing data for UID 0245@mlife: No columns to parse from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86c2e2-97e8-4149-b536-75a870471cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @lru_cache(maxsize=1)\n",
    "# def get_sleep_df(uid):\n",
    "#     try:\n",
    "#         # Load the CSV file for the given UID and cache the DataFrame\n",
    "#         sleep_df = pd.read_csv(f'sleep/{uid}.csv')\n",
    "#         sleep_df['calendarDate'] = pd.to_datetime(sleep_df['calendarDate'], errors='coerce').dt.date\n",
    "#         return sleep_df\n",
    "#     except pd.errors.ParserError as e:\n",
    "#         print(f\"Error parsing CSV for UID {uid}: {e}\")\n",
    "#         return None\n",
    "#     except FileNotFoundError as e:\n",
    "#         print(f\"File not found for UID {uid}: {e}\")\n",
    "#         return None\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing data for UID {uid}: {e}\")\n",
    "#         return None\n",
    "\n",
    "\n",
    "# def get_sleep_data(row):\n",
    "#     uid = row['uid']\n",
    "#     sleep_df = get_sleep_df(uid)\n",
    "\n",
    "#     if sleep_df is None:\n",
    "#         return None\n",
    "\n",
    "#     try:\n",
    "#         # Ensure timestamp and date\n",
    "#         time = pd.to_datetime(row['time'], errors='coerce')\n",
    "#         if pd.isna(time):\n",
    "#             return None\n",
    "#         date = time.date()\n",
    "\n",
    "#         # Sleep sessions on the same day or the day after\n",
    "#         relevant_sleep_df = sleep_df[\n",
    "#             (sleep_df['calendarDate'] == date) |\n",
    "#             (sleep_df['calendarDate'] == (date + timedelta(days=1)))\n",
    "#         ].copy()\n",
    "\n",
    "#         if relevant_sleep_df.empty:\n",
    "#             return False\n",
    "\n",
    "#         # Start and end timestamps for each session\n",
    "#         relevant_sleep_df = relevant_sleep_df.assign(\n",
    "#             startTime=pd.to_datetime(relevant_sleep_df['startTimeInSeconds'], unit='s')\n",
    "#                       + pd.to_timedelta(relevant_sleep_df['startTimeOffsetInSeconds'], unit='s'),\n",
    "#             endTime=lambda d: d['startTime'] + pd.to_timedelta(d['durationInSeconds'], unit='s')\n",
    "#         )\n",
    "\n",
    "#         # Overlap check at the given time\n",
    "#         overlap = (relevant_sleep_df['startTime'] <= time) & (relevant_sleep_df['endTime'] >= time)\n",
    "#         return bool(overlap.any())\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing data for UID {uid}: {e}\")\n",
    "#         return None\n",
    "\n",
    "\n",
    "# # Apply the function to loc_df using tqdm for progress tracking\n",
    "# tqdm.pandas()\n",
    "# loc_df['is_sleep'] = loc_df.progress_apply(get_sleep_data, axis=1)\n",
    "\n",
    "# # Filter the rows where sleep session data matches\n",
    "# loc_sleep = loc_df[loc_df['is_sleep'] == True]\n",
    "# loc_night = loc_sleep.copy()\n",
    "# display(loc_night.head(), loc_night.shape, loc_df.shape)\n",
    "\n",
    "\n",
    "# # TODO: Update loc_night to use the default range for uids who don't have enough sleep data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad36f2f5-bc6e-4a8c-abc6-15d0b7874fcb",
   "metadata": {},
   "source": [
    "# DBSCAN for Home Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45d969b",
   "metadata": {},
   "source": [
    "## Allowing multiple homes\n",
    "\n",
    "(Other version that assumed one home per participant seems to have been removed)\n",
    "\n",
    "**Notes for Use:**\n",
    "\n",
    "You'll need to decide how to define home locations. You can use my approach or modify it based on your needs.\n",
    "\n",
    "Key Considerations:\n",
    "- Most participants have one home throughout the study, but some move (e.g., to a new home, from family homes to college dorms).\n",
    "- Participants may occasionally spend days/weeks on a trip or stay at someone else's home.\n",
    "- My script only considers whether a certain numbre of data points exist in a location. It doesn't consider the temporal proximity of GPS points.\n",
    "\n",
    "I remember feeling reasonably satisfied with my script when inspecting the results. One strength of my script is that it includes plotting functionality to visualize how your parameter choices affect results.\n",
    "\n",
    "You may wish to use the Garmin sleep data or to define home locations differently. You may wish to define min_samples dynamically based on the total number of nighttime points a participant has. You may wish to use cluster medians instead of means for home locations. etc. Or you may find the current script sufficient.\n",
    "\n",
    "One note. DBSCAN defaults to Euclidean distance, so it doesn't account for the curviture of the Earth. Switching to something like Haversine might improve this. Though I'll say that results seemed reasonable based on visual inspection. I'm unsure how switching the metric would change the results or if it would necessitate reparamaterizing.\n",
    "\n",
    "**Technical Documentation:** \n",
    "\n",
    "The script groups nighttime location observations by user (`uid`). For each user, it runs density-based spatial clustering for applications with noise (DBSCAN) on latitude/longitude (converted to radians) with a ~0.1 km radius (`eps`) and a high minimum sample threshold (`min_samples=800`) to find dense “home” clusters. For each non-noise cluster, it computes a centroid as the home location and stores the resulting list in `home_coords`, along with the number of detected home locations in `num_of_homes`. Users without valid clusters receive `home_coords = NaN` and `num_of_homes = 0` (home locations are manually assigned for these users later). Results are returned in `loc_night`. I chose these parameters based on visual inspection of the results. With these parameters, most participants have one detected home location, which aligns with expectations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4aace2-92af-456a-8a5a-94bd1cd7a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_home_location_and_is_home(df):\n",
    "    # Parameters for DBSCAN\n",
    "    kms_per_radian = 6371.0088\n",
    "    epsilon = 0.1 / kms_per_radian  # 0.1 km radius\n",
    "    \n",
    "    # Convert lat/lon to radians for DBSCAN\n",
    "    df['lat_rad'] = np.radians(df['lat'])\n",
    "    df['lon_rad'] = np.radians(df['lon'])\n",
    "    coords = df[['lat_rad', 'lon_rad']].values\n",
    "    \n",
    "    # Run DBSCAN\n",
    "    # Results seem decent, but I arguably should've used something like haversine distance (DBSCAN defaults to metric='euclidean'). Unsure how this would change results.\n",
    "    db = DBSCAN(eps=epsilon, min_samples=800).fit(coords)\n",
    "    cluster_labels = db.labels_\n",
    "    \n",
    "    # Add cluster labels to the dataframe\n",
    "    df['home_cluster'] = cluster_labels\n",
    "    \n",
    "    # Filter out noise points\n",
    "    clusters = df[df['home_cluster'] != -1]\n",
    "    \n",
    "    # Store coordinates for the centroid of each home cluster\n",
    "    if not clusters.empty:\n",
    "        home_coords = []\n",
    "        unique_clusters = clusters['home_cluster'].unique()\n",
    "        \n",
    "        for cluster_label in unique_clusters:\n",
    "            cluster_points = clusters[clusters['home_cluster'] == cluster_label]\n",
    "            cluster_centroid = MultiPoint(cluster_points[['lon', 'lat']].values).centroid\n",
    "            home_coords.append((cluster_centroid.y, cluster_centroid.x))\n",
    "        \n",
    "        df['home_coords'] = [home_coords] * len(df) # Home coordinates list of tuples\n",
    "        df['num_of_homes'] = len(home_coords) # Number of home clusters identified\n",
    "    else:\n",
    "        # If no valid cluster found, fill with NaNs and set is_home to False\n",
    "        df['home_coords'] = np.nan\n",
    "        df['num_of_homes'] = 0\n",
    "    \n",
    "    return df\n",
    "\n",
    "loc_night = loc_night.groupby('uid').apply(identify_home_location_and_is_home).reset_index(drop=True)\n",
    "display(loc_night.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02e2d3a-3a09-47c7-9969-7a01581b841f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge home info to full dataframe\n",
    "display(loc_df.shape)\n",
    "home_info = loc_night[['uid', 'home_coords', 'num_of_homes']].drop_duplicates(subset='uid')\n",
    "loc_df = pd.merge(loc_df, home_info, on='uid', how='left')\n",
    "\n",
    "# could vectorize if too slow, arguably should use haversine but results would probably be about equivalent - geodesic probably about the same as haversine over small distances like these.\n",
    "def is_within_home_area(row, home_coords, radius=40): # When using uids 0011-0020 –– 20: 78,544, 40: 78,575, 50: 78668, 70: 79,099, 100: 79,371, home_cluster: 90,860\n",
    "    if isinstance(home_coords, float) and np.isnan(home_coords):\n",
    "        return np.nan\n",
    "    \n",
    "    point = (row['lat'], row['lon'])\n",
    "    for home in home_coords:\n",
    "        if geodesic(point, home).meters <= radius:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "loc_df['is_home'] = loc_df.apply(lambda row: is_within_home_area(row, home_coords=row['home_coords']), axis=1)\n",
    "display(loc_df.head(), loc_df.shape, loc_df[\"is_home\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62423473-f717-473b-93ae-9591ecc0e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_night['is_home'] = loc_night.apply(lambda row: is_within_home_area(row, home_coords=row['home_coords']), axis=1)\n",
    "loc_df[loc_df[\"is_home\"].isna()][\"uid\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701a3aa1-4031-414f-8be7-3f0b30de4ffd",
   "metadata": {},
   "source": [
    "(I think this might be when subsetting based on sleep data and whatever parameters I used; fewer participants missing clusters when using 10pm–7am subset)\n",
    "\n",
    "Garmin Missing Home Clusters for 23 uids:\n",
    "- 0102@mlife    15162\n",
    "- 0070@mlife    14827\n",
    "- 0196@mlife    13107\n",
    "- 0161@mlife    13023\n",
    "- 0167@mlife    12995\n",
    "- 0013@mlife    11307\n",
    "- 0238@mlife    11033\n",
    "- 0264@mlife    10786\n",
    "- 0030@mlife    10040\n",
    "- 0019@mlife     7558\n",
    "- 0138@mlife     6619\n",
    "- 0139@mlife     6458\n",
    "- 0169@mlife     4778\n",
    "- 0158@mlife     4264\n",
    "- 0188@mlife     3855\n",
    "- 0028@mlife     3356\n",
    "- 0245@mlife     1221\n",
    "- 0258@mlife     1012\n",
    "- 0191@mlife     1006\n",
    "- 0135@mlife      834\n",
    "- 0053@mlife      829\n",
    "- 0137@mlife      540\n",
    "- 0220@mlife      121"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fdb12c-cd7e-4d14-a653-cd9ccaa7f4e5",
   "metadata": {},
   "source": [
    "## Plot based on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48fb652-a842-47b6-8c03-29c079102c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to plot clusters for a specific participant on a map\n",
    "def plot_clusters_on_map(df, uid):\n",
    "    participant_data = df[df['uid'] == uid]\n",
    "    \n",
    "    # Return if there's no data for the uid\n",
    "    if participant_data.empty:\n",
    "        print(f\"No data available for participant {uid}\")\n",
    "        return\n",
    "    \n",
    "    folium_map = None\n",
    "    unique_clusters = participant_data['home_cluster'].unique()\n",
    "    colors = [\n",
    "        'blue', 'green', 'purple', 'orange', 'darkred', 'lightred', 'darkblue', \n",
    "        'darkgreen', 'cadetblue', 'darkpurple', 'pink', 'lightblue'\n",
    "    ]\n",
    "    marker_cluster = MarkerCluster()\n",
    "    \n",
    "    # Plot all coords and color based on cluster\n",
    "    for idx, cluster_label in enumerate(unique_clusters):\n",
    "        cluster_points = participant_data[participant_data['home_cluster'] == cluster_label]        \n",
    "        color = colors[idx % len(colors)] if cluster_label != -1 else 'gray'\n",
    "        \n",
    "        for _, row in cluster_points.iterrows():\n",
    "            folium.CircleMarker(\n",
    "                location=[row['lat'], row['lon']],\n",
    "                radius=5,\n",
    "                color=color,\n",
    "                fill=True,\n",
    "                fill_color=color,\n",
    "                fill_opacity=0.6,\n",
    "            ).add_to(marker_cluster)\n",
    "        \n",
    "        # For each home cluster (excluding noise), add a marker\n",
    "        if cluster_label != -1:\n",
    "            cluster_centroid = MultiPoint(cluster_points[['lon', 'lat']].values).centroid\n",
    "            if folium_map is None:\n",
    "                folium_map = folium.Map(location=[cluster_centroid.y, cluster_centroid.x], zoom_start=12)\n",
    "            \n",
    "            folium.Marker(\n",
    "                location=[cluster_centroid.y, cluster_centroid.x],\n",
    "                popup=f\"Home Location (Cluster {cluster_label})\",\n",
    "                icon=folium.Icon(color='red', icon='home'),\n",
    "            ).add_to(folium_map)\n",
    "    \n",
    "    # Add marker cluster to folium map\n",
    "    if folium_map is not None:\n",
    "        marker_cluster.add_to(folium_map)\n",
    "        return folium_map\n",
    "    else:\n",
    "        print(f\"No valid clusters found for participant {uid}\")\n",
    "        return None\n",
    "\n",
    "map_night = plot_clusters_on_map(loc_night, uid='0017@mlife')\n",
    "display(map_night)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1147d4bd-7882-4a70-9b70-5bc1ca3964cd",
   "metadata": {},
   "source": [
    "## Plot based on is_home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd92db-a5fa-44be-b03e-4703fd81537a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to plot clusters for a specific participant on a map\n",
    "def plot_clusters_on_map(df, uid):\n",
    "    participant_data = df[df['uid'] == uid]\n",
    "    \n",
    "    # Return if there's no data for the uid\n",
    "    if participant_data.empty:\n",
    "        print(f\"No data available for participant {uid}\")\n",
    "        return\n",
    "    \n",
    "    folium_map = None\n",
    "    marker_cluster = MarkerCluster()\n",
    "    \n",
    "    # Plot all coords and color based on whether the point is home or not\n",
    "    for _, row in participant_data.iterrows():\n",
    "        color = 'blue' if row['is_home'] else 'gray'\n",
    "        \n",
    "        folium.CircleMarker(\n",
    "            location=[row['lat'], row['lon']],\n",
    "            radius=5,\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_color=color,\n",
    "            fill_opacity=0.6,\n",
    "        ).add_to(marker_cluster)\n",
    "    \n",
    "    # Place home markers based on the first row's 'home_coords'\n",
    "    home_coords = participant_data.iloc[0]['home_coords']\n",
    "    if home_coords:\n",
    "        for coord in home_coords:\n",
    "            lat, lon = coord \n",
    "            if folium_map is None:\n",
    "                folium_map = folium.Map(location=[lat, lon], zoom_start=12)\n",
    "\n",
    "            folium.Marker(\n",
    "                location=[lat, lon],\n",
    "                popup=\"Home Location\",\n",
    "                icon=folium.Icon(color='red', icon='home'),\n",
    "            ).add_to(folium_map)\n",
    "    \n",
    "    # Add marker cluster to folium map\n",
    "    if folium_map is not None:\n",
    "        marker_cluster.add_to(folium_map)\n",
    "        return folium_map\n",
    "    else:\n",
    "        print(f\"No valid data found for participant {uid}\")\n",
    "        return None\n",
    "\n",
    "map_all = plot_clusters_on_map(loc_df, uid='0011@mlife')\n",
    "display(map_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a85517-815d-444d-bbf3-652f96db5e06",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Manual Home Identification for Participants Missing Home Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8af50be",
   "metadata": {},
   "source": [
    "No valid home clusters were identified for:\n",
    "- 0019@mlife    7558\n",
    "- 0158@mlife    4264\n",
    "- 0245@mlife    1221\n",
    "- 0258@mlife    1012\n",
    "- 0191@mlife    1006\n",
    "- 0135@mlife     834\n",
    "- 0053@mlife     829\n",
    "- 0137@mlife     540\n",
    "- 0220@mlife     121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90969370-4405-4252-9c8a-84d155199f32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loc_df = pd.read_csv(\"/Users/dawsonhaddox/Documents/Jacobson Lab/Avoidance-Mediation/time_at_home.csv\", usecols=lambda column: column != \"Unnamed: 0\")\n",
    "loc_df['time'] = pd.to_datetime(loc_df['time'])\n",
    "loc_df['home_coords'] = loc_df['home_coords'].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "loc_df['is_home'] = loc_df['is_home'].astype(bool) # maybe switch to 'boolean\n",
    "\n",
    "night_start = pd.to_datetime(\"22:00:00\", format='%H:%M:%S').time()\n",
    "night_end = pd.to_datetime(\"07:00:00\", format='%H:%M:%S').time()\n",
    "loc_dark = loc_df[(loc_df['time'].dt.time >= night_start) | (loc_df['time'].dt.time <= night_end)]\n",
    "\n",
    "display(loc_df.head(), loc_df.shape, loc_night.shape, loc_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26156d7-5c5c-4673-961b-8d400250ab55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to plot clusters for a specific participant on a map\n",
    "def plot_clusters_on_map(df, uid):\n",
    "    participant_data = df[df['uid'] == uid]\n",
    "    \n",
    "    # Return if there's no data for the uid\n",
    "    if participant_data.empty:\n",
    "        print(f\"No data available for participant {uid}\")\n",
    "        return\n",
    "    \n",
    "    folium_map = None\n",
    "    marker_cluster = MarkerCluster()\n",
    "    \n",
    "    # Plot all coords and color based on whether the point is home or not\n",
    "    display(participant_data.head())\n",
    "    for _, row in participant_data.iterrows():\n",
    "        color = 'blue' if row['is_home'] else 'gray'\n",
    "        \n",
    "        # Add a marker with a popup displaying the coordinates\n",
    "        folium.CircleMarker(\n",
    "            location=[row['lat'], row['lon']],\n",
    "            radius=5,\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_color=color,\n",
    "            fill_opacity=0.6,\n",
    "            popup=f\"Coordinates: {row['lat']}, {row['lon']}\"\n",
    "        ).add_to(marker_cluster)\n",
    "    \n",
    "    # Place home markers based on the first row's 'home_coords'\n",
    "    home_coords = participant_data.iloc[0]['home_coords']\n",
    "    \n",
    "    # Check if home_coords is not NaN or None before proceeding\n",
    "    if isinstance(home_coords, (list, tuple)) and len(home_coords) > 0:\n",
    "        for coord in home_coords:\n",
    "            lat, lon = coord\n",
    "            if folium_map is None:\n",
    "                folium_map = folium.Map(location=[lat, lon], zoom_start=12)\n",
    "\n",
    "            folium.Marker(\n",
    "                location=[lat, lon],\n",
    "                popup=f\"Home Location: {lat}, {lon}\",\n",
    "                icon=folium.Icon(color='red', icon='home'),\n",
    "            ).add_to(folium_map)\n",
    "    \n",
    "    # If no home_coords, create a map with default zoom on the first location\n",
    "    if folium_map is None:\n",
    "        # Use the first data point to initialize the map\n",
    "        first_location = [participant_data.iloc[0]['lat'], participant_data.iloc[0]['lon']]\n",
    "        folium_map = folium.Map(location=first_location, zoom_start=12)\n",
    "    \n",
    "    # Add marker cluster to folium map\n",
    "    marker_cluster.add_to(folium_map)\n",
    "    \n",
    "    # Add LatLngPopup to allow clicking anywhere on the map to get coordinates\n",
    "    folium_map.add_child(folium.LatLngPopup())\n",
    "\n",
    "    return folium_map\n",
    "\n",
    "map_all = plot_clusters_on_map(loc_dark, uid='0019@mlife')\n",
    "display(map_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22947df1-024f-4abf-99d2-70145e944158",
   "metadata": {},
   "source": [
    "Manual Home Clusters (lat,lon)\n",
    "- 0019@mlife    7558: 34.80717923333333, -83.03800723333335 *\n",
    "- 0158@mlife    4264: 43.076911474285716, -75.60749948571429 *\n",
    "- 0245@mlife    1221: 34.61370630222222, -86.98471391333331\n",
    "- 0258@mlife    1012: 36.48292789146346, -80.59133030975616\n",
    "- 0191@mlife    1006: 43.16906334363637, -89.26362676545465; 42.14770811999999, -88.01730834\n",
    "- 0135@mlife     834: 42.636156193650805, -84.60205366984124\n",
    "- 0053@mlife     829: 35.04374041512605, -78.86898512436973\n",
    "- 0137@mlife     540: 39.9749601888889, -105.08223831111113\n",
    "- 0220@mlife     121: 32.759629193877544, -117.08836552040808\n",
    "\n",
    "Garmin Manual Home Clusters (lat,lon)\n",
    "- 0102@mlife    15162: 42.57890806870229, -71.78348419618322\n",
    "- 0070@mlife    14827: 30.118677459999994, -97.39395718571429\n",
    "- 0196@mlife    13107: 29.69164973130435, -96.58995418173907; 29.71451887815126, -96.53967332352948\n",
    "- 0161@mlife    13023: 37.21932475507247, -80.44992237391305 (Had no Garmin sleep data)\n",
    "- 0167@mlife    12995: 41.14155916964285, -104.77647582678574\n",
    "- 0013@mlife    11307: 33.20472388333334, -97.13972475833329 \n",
    "- 0238@mlife    11033: 40.64433656129033, -74.26836620322581\n",
    "- 0264@mlife    10786: 41.84367935, -103.66702671666668\n",
    "- 0030@mlife    10040: 43.62704169705883, -72.93721083529411\n",
    "- 0019@mlife     7558: 34.80717923333333, -83.03800723333335\n",
    "- 0138@mlife     6619: 41.31010776923077, -72.92940483846155\n",
    "- 0139@mlife     6458: 42.18948781111111, -85.54333844444446\n",
    "- 0169@mlife     4778: 37.00420913448274, -93.0815587747126\n",
    "- 0158@mlife    4264: 43.076911474285716, -75.60749948571429\n",
    "- 0188@mlife     3855: 37.62998183478261, -97.36649026666667\n",
    "- 0028@mlife     3356: 39.0247310154412, -122.67191622647056\n",
    "- 0245@mlife    1221: 34.61370630222222, -86.98471391333331\n",
    "- 0258@mlife    1012: 36.48292789146346, -80.59133030975616\n",
    "- 0191@mlife    1006: 43.16906334363637, -89.26362676545465; 42.14770811999999, -88.01730834\n",
    "- 0135@mlife     834: 42.636156193650805, -84.60205366984124\n",
    "- 0053@mlife     829: 35.04374041512605, -78.86898512436973\n",
    "- 0137@mlife     540: 39.9749601888889, -105.08223831111113\n",
    "- 0220@mlife     121: 32.759629193877544, -117.08836552040808"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f039e5-87e3-4103-b095-cb63c6bb2401",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dictionary with uid as keys and corresponding (lat, lon) values as tuples\n",
    "manual_home_clusters = {\n",
    "    \"0019@mlife\": [(34.80717923333333, -83.03800723333335)],\n",
    "    \"0158@mlife\": [(43.076911474285716, -75.60749948571429)],\n",
    "    \"0245@mlife\": [(34.61370630222222, -86.98471391333331)],\n",
    "    \"0258@mlife\": [(36.48292789146346, -80.59133030975616)],\n",
    "    \"0191@mlife\": [(43.16906334363637, -89.26362676545465), (42.14770811999999, -88.01730834)],\n",
    "    \"0135@mlife\": [(42.636156193650805, -84.60205366984124)],\n",
    "    \"0053@mlife\": [(35.04374041512605, -78.86898512436973)],\n",
    "    \"0137@mlife\": [(39.9749601888889, -105.08223831111113)],\n",
    "    \"0220@mlife\": [(32.759629193877544, -117.08836552040808)],\n",
    "}\n",
    "\n",
    "# manual_home_clusters = {\n",
    "#     \"0019@mlife\": [(34.80717923333333, -83.03800723333335)],\n",
    "#     \"0158@mlife\": [(43.076911474285716, -75.60749948571429)],\n",
    "#     \"0245@mlife\": [(34.61370630222222, -86.98471391333331)],\n",
    "#     \"0258@mlife\": [(36.48292789146346, -80.59133030975616)],\n",
    "#     \"0191@mlife\": [(43.16906334363637, -89.26362676545465), (42.14770811999999, -88.01730834)],\n",
    "#     \"0135@mlife\": [(42.636156193650805, -84.60205366984124)],\n",
    "#     \"0053@mlife\": [(35.04374041512605, -78.86898512436973)],\n",
    "#     \"0137@mlife\": [(39.9749601888889, -105.08223831111113)],\n",
    "#     \"0220@mlife\": [(32.759629193877544, -117.08836552040808)],\n",
    "#     \"0102@mlife\": [(42.57890806870229, -71.78348419618322)],\n",
    "#     \"0070@mlife\": [(30.118677459999994, -97.39395718571429)],\n",
    "#     \"0196@mlife\": [(29.69164973130435, -96.58995418173907), (29.71451887815126, -96.53967332352948)],\n",
    "#     \"0161@mlife\": [(37.21932475507247, -80.44992237391305)],\n",
    "#     \"0167@mlife\": [(41.14155916964285, -104.77647582678574)],\n",
    "#     \"0013@mlife\": [(33.20472388333334, -97.13972475833329)],\n",
    "#     \"0238@mlife\": [(40.64433656129033, -74.26836620322581)],\n",
    "#     \"0264@mlife\": [(41.84367935, -103.66702671666668)],\n",
    "#     \"0030@mlife\": [(43.62704169705883, -72.93721083529411)],\n",
    "#     \"0138@mlife\": [(41.31010776923077, -72.92940483846155)],\n",
    "#     \"0139@mlife\": [(42.18948781111111, -85.54333844444446)],\n",
    "#     \"0169@mlife\": [(37.00420913448274, -93.0815587747126)],\n",
    "#     \"0188@mlife\": [(37.62998183478261, -97.36649026666667)],\n",
    "#     \"0028@mlife\": [(39.0247310154412, -122.67191622647056)],\n",
    "# }\n",
    "\n",
    "# Function to set home_coords for each uid\n",
    "def set_home_coords(df, home_clusters):\n",
    "    df['home_coords'] = df.apply(\n",
    "        lambda row: home_clusters.get(row['uid'], row['home_coords']), axis=1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Apply function to loc_df\n",
    "loc_df = set_home_coords(loc_df, manual_home_clusters)\n",
    "\n",
    "# Update is_home only for UIDs in manual_home_clusters\n",
    "def is_within_home_area(row, home_coords, radius=40): \n",
    "    if isinstance(home_coords, float) and np.isnan(home_coords):\n",
    "        return np.nan\n",
    "    \n",
    "    point = (row['lat'], row['lon'])\n",
    "    for home in home_coords:\n",
    "        if geodesic(point, home).meters <= radius:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Update is_home column only for rows where uid exists in manual_home_clusters\n",
    "loc_df['is_home'] = loc_df.apply(\n",
    "    lambda row: is_within_home_area(row, home_coords=row['home_coords']) if row['uid'] in manual_home_clusters else row['is_home'], axis=1\n",
    ")\n",
    "\n",
    "loc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f42c23-b1b6-42c4-bbef-bbd56bd97429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(loc_df[loc_df[\"is_home\"].isna()][\"uid\"].value_counts(), loc_df[loc_df[\"home_coords\"].isna()][\"uid\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939c7fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "# loc_df.to_csv('time_at_home.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756473ae-2aaf-46ec-a730-71e6529ca670",
   "metadata": {},
   "source": [
    "#  (Extra) Connect with phone unlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce603329-8e36-45e6-8d46-d9ff48663c87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @lru_cache(maxsize=1)\n",
    "# def get_unlock_data(uid, date):\n",
    "#     try:\n",
    "#         unlock_df = pd.read_csv(f'unlock_clean/{uid}_unlock.csv', index_col='date')\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"File for UID {uid} not found.\")\n",
    "#         return {}\n",
    "#     except pd.errors.ParserError as e:\n",
    "#         print(f\"Error parsing CSV for UID {uid}: {e}\")\n",
    "#         return {}\n",
    "    \n",
    "#     matching_row = unlock_df[unlock_df.index.str.startswith(date)]\n",
    "    \n",
    "#     if matching_row.empty:\n",
    "#         print(f\"Date {date} not found for UID {uid}\")\n",
    "#         return {}\n",
    "\n",
    "#     unlock_list = ast.literal_eval(matching_row.iloc[0]['data'])\n",
    "#     return {int(time): status for time, status in enumerate(unlock_list)}\n",
    "\n",
    "# def determine_is_unlock(row):\n",
    "#     \"\"\"\n",
    "#     Determines if the user has unlocked at the given timestamp (row['time']).\n",
    "#     \"\"\"\n",
    "#     uid = row['uid']\n",
    "#     date = row['time'].strftime('%Y-%m-%d')\n",
    "#     time_in_seconds = row['time'].hour * 3600 + row['time'].minute * 60 + row['time'].second\n",
    "#     unlock_dict = get_unlock_data(uid, date)\n",
    "    \n",
    "#     if not unlock_dict:\n",
    "#         return None\n",
    "    \n",
    "#     return unlock_dict.get(time_in_seconds, False)\n",
    "\n",
    "# tqdm.pandas()\n",
    "# loc_df['is_unlock'] = loc_df.progress_apply(lambda row: determine_is_unlock(row), axis=1)\n",
    "# # loc_df['is_unlock'] = loc_df.progress_apply(\n",
    "# #     lambda row: determine_is_unlock(row) if row['uid'] in manual_home_clusters or pd.isna(row['is_unlock']) else row['is_unlock'], \n",
    "# #     axis=1\n",
    "# # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e83428f-c2cc-4c50-bf96-579b95822dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loc_df[loc_df['is_unlock'].isna()]['uid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d299f2-95b5-49aa-a906-18db82db3781",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loc_df['unlock_away_from_home'] = (loc_df['is_home'] == False) & (loc_df['is_unlock'] == 1.0)\n",
    "# loc_df.sample(n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f80cef-6fbb-4925-bbb2-6bd2e4b1b981",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loc_df[loc_df[\"is_home\"].isna()][\"uid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77317bb7-e7f7-43ab-8445-fd77e0a401c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loc_df[loc_df[\"is_unlock\"].isna()][\"uid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f448af67-b725-4a4a-9d8c-97916e45da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc_df.to_csv('time_at_home.csv', index=False)\n",
    "# loc_df.to_csv('time_at_home_garmin.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c4cb8-2aff-4436-8ba5-3efc372edde1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Agreement btwn Default Nighttime Subset and Garmin Sleep Subset \n",
    "\n",
    "(unsure if this was ever finished, but I remember preliminary results showed they worked equally well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54afb72f-8eef-42a9-8a72-43b7ec11d659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from collections import defaultdict\n",
    "# from geopy.distance import great_circle, geodesic\n",
    "# from shapely.geometry import MultiPoint\n",
    "# from sklearn.cluster import DBSCAN\n",
    "# import matplotlib.pyplot as plt\n",
    "# import folium6\n",
    "# from folium.plugins import MarkerCluster\n",
    "# from functools import lru_cache\n",
    "# from tqdm import tqdm\n",
    "# from datetime import datetime, timedelta\n",
    "# import ast\n",
    "# import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4dc83-e9a7-4432-b84d-0f5d2cd6db7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# default_df = pd.read_csv(\"/Users/dawsonhaddox/Documents/Jacobson Lab/Avoidance-Mediation/time_at_home.csv\", usecols=lambda column: column != \"Unnamed: 0\")\n",
    "# garmin_df = pd.read_csv(\"/Users/dawsonhaddox/Documents/Jacobson Lab/Avoidance-Mediation/time_at_home_garmin.csv\", usecols=lambda column: column != \"Unnamed: 0\")\n",
    "\n",
    "# display(\"Default Data:\", default_df.head(), default_df.shape, garmin_df.head(), garmin_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f564d0f2-0bb2-4051-819b-fdf7e2b1948f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Function to ensure that 'home_coords' is properly formatted as a list of tuples of floats\n",
    "# def validate_and_cast(row):\n",
    "#     row = ast.literal_eval(row)\n",
    "#     return [(float(a), float(b)) for a, b in row if isinstance(a, (int, float)) and isinstance(b, (int, float))]\n",
    "\n",
    "# # Apply the function to 'home_coords' to ensure it's properly formatted and cast\n",
    "# garmin_df['home_coords'] = garmin_df['home_coords'].apply(validate_and_cast)\n",
    "# default_df['home_coords'] = default_df['home_coords'].apply(validate_and_cast)\n",
    "\n",
    "# # Recreate 'num_of_homes' to count the number of tuples\n",
    "# garmin_df[\"num_of_homes\"] = garmin_df['home_coords'].apply(len)\n",
    "# default_df[\"num_of_homes\"] = default_df['home_coords'].apply(len)\n",
    "\n",
    "# display(garmin_df, default_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b520e490-2441-46b5-81f7-cd3012378665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Drop duplicate uids\n",
    "# default_subset = default_df.drop_duplicates(subset=['uid'], keep='first')\n",
    "# garmin_subset = garmin_df.drop_duplicates(subset=['uid'], keep='first')\n",
    "\n",
    "# # Merge the two subsets on 'uid' and compare the lengths of 'num_of_homes'\n",
    "# merged_df = pd.merge(default_subset, garmin_subset, on='uid', suffixes=('_default', '_garmin'))\n",
    "\n",
    "# # Filter rows where the lengths of 'num_of_homes' are different\n",
    "# result_df = merged_df[merged_df['num_of_homes_default'] != merged_df['num_of_homes_garmin']]\n",
    "# display(result_df, result_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7904bdc-0dfb-44d5-b890-40afa0154688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from geopy.distance import great_circle\n",
    "\n",
    "# def haversine_distance(coord1, coord2):\n",
    "#     return great_circle(coord1, coord2).meters\n",
    "\n",
    "# def average_distance(coords1, coords2):\n",
    "#     # Ensure that both lists have the same length\n",
    "#     if len(coords1) != len(coords2):\n",
    "#         raise ValueError(\"Coordinate lists must have the same length.\")\n",
    "    \n",
    "#     # Compute distances between corresponding coordinates\n",
    "#     distances = [haversine_distance(coord1, coord2) for coord1, coord2 in zip(coords1, coords2)]\n",
    "#     return np.mean(distances) if distances else None\n",
    "\n",
    "# # Initialize dictionary to store average distances and coordinates\n",
    "# average_distances = {\n",
    "#     'uid': [],\n",
    "#     'home_coords_default': [],\n",
    "#     'home_coords_garmin': [],\n",
    "#     'average_distance': []\n",
    "# }\n",
    "\n",
    "# # Merge filtered DataFrames on 'uid'\n",
    "# merged_filtered_df = pd.merge(default_subset_filtered, garmin_subset_filtered, on='uid', suffixes=('_default', '_garmin'))\n",
    "\n",
    "# # Compute average distances and store coordinates for each uid\n",
    "# for index, row in merged_filtered_df.iterrows():\n",
    "#     uid = row['uid']\n",
    "#     coords_default = row['home_coords_default']\n",
    "#     coords_garmin = row['home_coords_garmin']\n",
    "    \n",
    "#     # Ensure both coordinate lists have the same length\n",
    "#     if len(coords_default) != len(coords_garmin):\n",
    "#         continue\n",
    "    \n",
    "#     avg_distance = average_distance(coords_default, coords_garmin)\n",
    "    \n",
    "#     # Append results to the dictionary\n",
    "#     average_distances['uid'].append(uid)\n",
    "#     average_distances['home_coords_default'].append(coords_default)\n",
    "#     average_distances['home_coords_garmin'].append(coords_garmin)\n",
    "#     average_distances['average_distance'].append(avg_distance)\n",
    "\n",
    "# # Convert to DataFrame for better visualization\n",
    "# average_distances_df = pd.DataFrame(average_distances)\n",
    "\n",
    "# # Filter to rows where the average distance is more than one meter\n",
    "# filtered_average_distances_df = average_distances_df[average_distances_df['average_distance'] > 5.0]\n",
    "\n",
    "# # Display the filtered DataFrame along with its shape and summary statistics\n",
    "# display(filtered_average_distances_df, filtered_average_distances_df.shape, average_distances_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c090cbe-d5c7-4abf-a73c-4c93aafd545c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Convert the 'time' column to datetime format\n",
    "# default_df['time'] = pd.to_datetime(garmin_df['time'])\n",
    "\n",
    "# # Define the nighttime range\n",
    "# night_start = pd.to_datetime(\"22:00:00\", format='%H:%M:%S').time()\n",
    "# night_end = pd.to_datetime(\"07:00:00\", format='%H:%M:%S').time()\n",
    "\n",
    "# # Filter data to nighttime hours\n",
    "# night_df = default_df[(default_df['time'].dt.time >= night_start) | (default_df['time'].dt.time <= night_end)]\n",
    "\n",
    "# sleep_df = garmin_df[garmin_df['is_sleep']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1591cfc2-2457-4f65-8eba-906743ecb9fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Function to plot clusters for a specific participant on a map\n",
    "# def plot_clusters_on_map(df, uid):\n",
    "#     participant_data = df[df['uid'] == uid]\n",
    "    \n",
    "#     # Return if there's no data for the uid\n",
    "#     if participant_data.empty:\n",
    "#         print(f\"No data available for participant {uid}\")\n",
    "#         return\n",
    "    \n",
    "#     folium_map = None\n",
    "#     marker_cluster = MarkerCluster()\n",
    "    \n",
    "#     # Plot all coords and color based on whether the point is home or not\n",
    "#     display(participant_data.head())\n",
    "#     for _, row in participant_data.iterrows():\n",
    "#         color = 'blue' if row['is_home'] else 'gray'\n",
    "        \n",
    "#         # Add a marker with a popup displaying the coordinates\n",
    "#         folium.CircleMarker(\n",
    "#             location=[row['lat'], row['lon']],\n",
    "#             radius=5,\n",
    "#             color=color,\n",
    "#             fill=True,\n",
    "#             fill_color=color,\n",
    "#             fill_opacity=0.6,\n",
    "#             popup=f\"Coordinates: {row['lat']}, {row['lon']}\"\n",
    "#         ).add_to(marker_cluster)\n",
    "    \n",
    "#     # Place home markers based on the first row's 'home_coords'\n",
    "#     home_coords = participant_data.iloc[0]['home_coords']\n",
    "    \n",
    "#     # Check if home_coords is not NaN or None before proceeding\n",
    "#     if isinstance(home_coords, (list, tuple)) and len(home_coords) > 0:\n",
    "#         for coord in home_coords:\n",
    "#             lat, lon = coord\n",
    "#             if folium_map is None:\n",
    "#                 folium_map = folium.Map(location=[lat, lon], zoom_start=12)\n",
    "\n",
    "#             folium.Marker(\n",
    "#                 location=[lat, lon],\n",
    "#                 popup=f\"Home Location: {lat}, {lon}\",\n",
    "#                 icon=folium.Icon(color='red', icon='home'),\n",
    "#             ).add_to(folium_map)\n",
    "    \n",
    "#     # If no home_coords, create a map with default zoom on the first location\n",
    "#     if folium_map is None:\n",
    "#         # Use the first data point to initialize the map\n",
    "#         first_location = [participant_data.iloc[0]['lat'], participant_data.iloc[0]['lon']]\n",
    "#         folium_map = folium.Map(location=first_location, zoom_start=12)\n",
    "    \n",
    "#     # Add marker cluster to folium map\n",
    "#     marker_cluster.add_to(folium_map)\n",
    "    \n",
    "#     # Add LatLngPopup to allow clicking anywhere on the map to get coordinates\n",
    "#     folium_map.add_child(folium.LatLngPopup())\n",
    "\n",
    "#     return folium_map\n",
    "\n",
    "# map_all = plot_clusters_on_map(sleep_df, uid='0026@mlife')\n",
    "# display(map_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gps_time_at_home",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
